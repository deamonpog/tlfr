{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52519cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import threading\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "from collections import deque\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dccea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterLookupForResearch:\n",
    "\n",
    "    def __init__(self, in_last_use):\n",
    "        self.read_tokens()\n",
    "        #\n",
    "        # Follower Lookup RateLimit : 15 lookups per 15 minutes\n",
    "        self.followers_lookups = deque(maxlen=15)\n",
    "        self.followers_lookups.extend((datetime.datetime.now() - in_last_use for i in range(15)))\n",
    "        #\n",
    "        # User Lookup RateLimit : 300 lookups per 15 minutes\n",
    "        self.user_lookups = deque(maxlen=300)\n",
    "        self.user_lookups.extend((datetime.datetime.now() - in_last_use for i in range(300)))\n",
    "        #\n",
    "        # Users lookup rate limit: 300 lookups per 15 minutes\n",
    "        self.users_lookups = deque(maxlen=300)\n",
    "        self.users_lookups.extend((datetime.datetime.now() - in_last_use for i in range(300)))\n",
    "        \n",
    "    # -------------------- internal AUTHENTICATION ------------------------#\n",
    "    def read_tokens(self):\n",
    "        # Get bearer token\n",
    "        with open('../SETTINGS/secrets.json') as f:\n",
    "            secrets = json.load(f)\n",
    "        self.bearer_token = secrets['BEARERTOKEN']\n",
    "        \n",
    "    def bearer_oauth(self, r):\n",
    "        \"\"\"\n",
    "        Method required by bearer token authentication.\n",
    "        \"\"\"\n",
    "\n",
    "        r.headers[\"Authorization\"] = f\"Bearer {self.bearer_token}\"\n",
    "        r.headers[\"User-Agent\"] = \"v2FollowersLookupPython\"\n",
    "        return r\n",
    "\n",
    "    # -------------------- internal CONNECT ENDPOINT ------------------------#\n",
    "    def connect_to_endpoint(self, url, params):\n",
    "        response = requests.request(\"GET\", url, auth=self.bearer_oauth, params=params)\n",
    "        print(response.status_code)\n",
    "        if response.status_code != 200:\n",
    "            #print(response)\n",
    "            #print(response.json())\n",
    "            raise Exception(\n",
    "                \"Request returned an error: {} {}\".format(\n",
    "                    response.status_code, response.text\n",
    "                )\n",
    "            )\n",
    "        return response.json()\n",
    "    \n",
    "     # -------------------- internal WAIT FOR ENDPOINT TIME ------------------------#\n",
    "    def wait_rate_limit(self, in_per_minutes, in_timestamp_list):\n",
    "        per_seconds = in_per_minutes * 60 + 1\n",
    "        current_time = datetime.datetime.now()\n",
    "        elapsed_time = current_time - in_timestamp_list[0]\n",
    "        if elapsed_time >= datetime.timedelta(seconds=per_seconds):\n",
    "            in_timestamp_list.append(current_time)\n",
    "        else:\n",
    "            print(f\"Waiting for {per_seconds - elapsed_time.seconds}\")\n",
    "            time.sleep(per_seconds - elapsed_time.seconds)\n",
    "            current_time = datetime.datetime.now()\n",
    "            in_timestamp_list.append(current_time)\n",
    "    \n",
    "    # -------------------- inernal CREATE URLS ------------------------#\n",
    "    def create_url_follower_lookup(self, in_user_id):\n",
    "        return \"https://api.twitter.com/2/users/{}/followers\".format(in_user_id)\n",
    "\n",
    "    def create_url_get_user_by_name(self, in_username):\n",
    "        return f\"https://api.twitter.com/2/users/by/username/{in_username}\"\n",
    "    \n",
    "    def create_url_get_users_by_ids(self):\n",
    "        return f\"https://api.twitter.com/2/users\"\n",
    "\n",
    "    # -------------------- API ------------------------#\n",
    "    def get_user_id_by_name(self, in_username):\n",
    "        url = self.create_url_get_user_by_name(in_username)\n",
    "        params = {\"user.fields\": \"public_metrics,verified,withheld,created_at,protected,url,location\"}\n",
    "        self.wait_rate_limit(15, self.user_lookups)\n",
    "        json_response = self.connect_to_endpoint(url, params)\n",
    "        return json_response\n",
    "    \n",
    "    def get_users_by_ids(self, in_user_id_list):\n",
    "        chunk_size = 100\n",
    "        data_length = len(in_user_id_list)\n",
    "        data_chunks = (in_user_id_list[i:i+chunk_size] for i in range(0, data_length, chunk_size))\n",
    "        results = []\n",
    "        for chunk in data_chunks:\n",
    "            comm_sprtd_ids = \",\".join((str(e) for e in chunk))\n",
    "            url = self.create_url_get_users_by_ids()\n",
    "            params = {\"user.fields\": \"public_metrics,verified,withheld,created_at,protected,url,location\",\n",
    "                      \"ids\":comma_sprtd_ids}\n",
    "            self.wait_rate_limit(15, self.users_lookups)\n",
    "            json_response = self.connect_to_endpoint(url, params)\n",
    "            results.append(json_response['data'])\n",
    "        results = reduce(lambda x,y: x+y, results)\n",
    "        return results\n",
    "\n",
    "    def get_all_followers(self, in_user_id):\n",
    "        print(f\"Followers of :{in_user_id}\")\n",
    "        url = self.create_url_follower_lookup(in_user_id)\n",
    "        current_params = {\"user.fields\": \"public_metrics,verified,withheld,created_at,protected,url,location\",\n",
    "                          \"max_results\":1000}\n",
    "        self.wait_rate_limit(15, self.followers_lookups)\n",
    "        json_response = self.connect_to_endpoint(url, current_params)\n",
    "        results = [json_response['data']]\n",
    "        while \"next_token\" in json_response[\"meta\"]:\n",
    "            current_params[\"pagination_token\"] = json_response[\"meta\"][\"next_token\"]\n",
    "            self.wait_rate_limit(15, self.followers_lookups)\n",
    "            json_response = self.connect_to_endpoint(url, current_params)\n",
    "            results.append(json_response['data'])\n",
    "        results = reduce(lambda x,y: x+y, results)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bca55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_COLUMNS = ['created_at', 'id', 'location', 'name', 'protected', 'url', 'username', 'verified']\n",
    "\n",
    "PUBLIC_METRIC_COLUMNS = ['followers_count', 'following_count', 'tweet_count', 'listed_count']\n",
    "\n",
    "class BatchLookup:\n",
    "    def save_users_to_df(in_user_list):\n",
    "        data = []\n",
    "        for user_basic_data in in_user_list:\n",
    "            #print(user_basic_data)\n",
    "            cols1 = [(user_basic_data[c] if c in user_basic_data else '') for c in MAIN_COLUMNS]\n",
    "            cols2 = [(user_basic_data['public_metrics'][c]) for c in PUBLIC_METRIC_COLUMNS]\n",
    "            data.append(cols1 + cols2)\n",
    "        return pd.DataFrame(data, columns = MAIN_COLUMNS + PUBLIC_METRIC_COLUMNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cc1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlfr = TwitterLookupForResearch(datetime.timedelta(seconds=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af098659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User list data from Twitter/Brandwatch\n",
    "df = pd.read_csv( glob.glob('C:\\STUFF\\RESEARCH\\TENet\\DATA\\Tweets\\*')[0], skiprows=6 )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b9806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_list = list(df['Twitter Author ID'].unique())\n",
    "users_list.sort()\n",
    "users_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fb17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_df = pd.DataFrame([], columns = MAIN_COLUMNS + PUBLIC_METRIC_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555679b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_chunk_size = 10\n",
    "user_chunks = ([users_list[i:i+user_chunk_size] for i in range(len(users_list))])\n",
    "user_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c242f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for chunk_idx, this_user_chunk in enumerate(user_chunks):\n",
    "    print(f\"Chunk {chunk_idx} Started.\")\n",
    "    chunk_user_df_list = []\n",
    "    for user_id in this_user_chunk:\n",
    "        print(f\"Looking up : {user_id}. {i} of {len(users_list)} users done.\")\n",
    "        if os.path.exists(\"C:/STUFF/RESEARCH/TENet/DATA/Followers/\" + f\"followers_{user_id}.csv\"):\n",
    "            print(\"Already exists.\")\n",
    "            continue\n",
    "        followers = tlfr.get_all_followers(user_id)\n",
    "        followers_df = BatchLookup.save_users_to_df(followers)\n",
    "        chunk_user_df_list.append(followers_df)\n",
    "        followers_df['id'].to_csv(\"C:/STUFF/RESEARCH/TENet/DATA/Followers/\" + f\"followers_{user_id}.csv\",index=False)\n",
    "        i += 1\n",
    "    if len(chunk_user_df_list) > 0:\n",
    "        chunk_users_df = pd.concat(chunk_user_df_list).drop_duplicates()\n",
    "        chunk_users_df.to_csv(\"C:/STUFF/RESEARCH/TENet/DATA/Followers/\" + f\"chunk_{chunk_idx}_u{i-user_chunk_size}_u{i}.csv\", index=False)\n",
    "        all_users_df.append(chunk_users_df)\n",
    "print(\"--ALL DONE--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_df.drop_duplicates().to_csv(\"C:/STUFF/RESEARCH/TENet/DATA/Followers/FollowerProfiles2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tlfr.get_user_id_by_name('cathura666')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchLookup.save_users_to_df(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603092ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
